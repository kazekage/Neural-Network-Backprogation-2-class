{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 5 part 2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XjLpOeFg0Wku",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "\n",
        "\n",
        "X = [[1, 0],\n",
        "                  [0, 1],\n",
        "                  [0, -1],\n",
        "                  [-1, 0]]\n",
        "\n",
        "y = [0, 1, 1, 0]\n",
        "\n",
        "        \n",
        "        \n",
        "class1_x1 = np.array(random.sample(range(2, 100), 48))\n",
        "class1_x2 = np.array(np.random.rand(48))\n",
        "\n",
        "random_x1c1 = np.array(random.sample(range(0, 48), 20))\n",
        "random_x2c1 = np.array(random.sample(range(0, 48), 20))\n",
        "class1_x1[random_x1c1] = class1_x1[random_x1c1]*-1\n",
        "class1_x2[random_x2c1] = class1_x2[random_x2c1]*-1\n",
        "\n",
        "class2_x1 = np.array(np.random.rand(48))\n",
        "class2_x2 = np.array(random.sample(range(2, 100), 48))\n",
        "\n",
        "random_x1c2 = np.array(random.sample(range(0, 48), 20))\n",
        "random_x2c2 = np.array(random.sample(range(0, 48), 20))\n",
        "class2_x1[random_x1c2] = class2_x1[random_x1c2]*-1\n",
        "class2_x2[random_x2c2] = class2_x2[random_x2c2]*-1\n",
        "\n",
        "for i in range(len(class1_x1)):\n",
        "  X.append([class1_x1[i], class1_x2[i]])\n",
        "  y.append(0)\n",
        "\n",
        "for i in range(len(class1_x1)):\n",
        "  X.append([class2_x1[i], class2_x2[i]])\n",
        "  y.append(1)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jS1YQ5NF0quN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, Y = X.T, Y.reshape(1, Y.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6EAztBOQ1EeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def layer_sizes(X, Y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- input dataset of shape (input size, number of examples)\n",
        "    Y -- labels of shape (output size, number of examples)\n",
        "    \n",
        "    Returns:\n",
        "    n_x -- the size of the input layer\n",
        "    n_h -- the size of the hidden layer\n",
        "    n_y -- the size of the output layer\n",
        "    \"\"\"\n",
        "    n_x = X.shape[0] # size of input layer`\n",
        "    n_h = 2\n",
        "    n_y =Y.shape[0] # size of output layer\n",
        "    return (n_x, n_h, n_y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fWibdtHy1c5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    n_x -- size of the input layer\n",
        "    n_h -- size of the hidden layer\n",
        "    n_y -- size of the output layer\n",
        "    \n",
        "    Returns:\n",
        "    params -- python dictionary containing your parameters:\n",
        "                    W1 -- weight matrix of shape (n_h, n_x)\n",
        "                    b1 -- bias vector of shape (n_h, 1)\n",
        "                    W2 -- weight matrix of shape (n_y, n_h)\n",
        "                    b2 -- bias vector of shape (n_y, 1)\n",
        "    \"\"\"\n",
        "        \n",
        "    W1 = 2*np.random.random((n_h,n_x)) -1\n",
        "    b1 = np.zeros(shape=(n_h, 1))\n",
        "    \n",
        "    W2 = 2*np.random.random((n_h,n_h)) -1\n",
        "    b2 = np.zeros(shape=(n_h, 1))\n",
        "    \n",
        "    W3 = 2*np.random.random((n_y,n_h)) -1\n",
        "    b3 = np.zeros(shape=(n_y, 1))\n",
        "    \n",
        "    print (W2.shape)\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "    return parameters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N8mnuRv34-aO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    X -- input data of size (n_x, m)\n",
        "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
        "    \n",
        "    Returns:\n",
        "    A2 -- The sigmoid output of the second activation\n",
        "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
        "    \"\"\"\n",
        "    # Retrieve each parameter from the dictionary \"parameters\"\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
        "    Z1 = np.matmul(W1, X) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.matmul(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    Z3 = np.matmul(W3, A2) + b3\n",
        "    A3 = sigmoid(Z3)\n",
        "    \n",
        "    cache = {\"Z1\": Z1,\n",
        "             \"A1\": A1,\n",
        "             \"Z2\": Z2,\n",
        "             \"A2\": A2,\n",
        "             \"Z3\": Z3,\n",
        "             \"A3\": A3}\n",
        "    \n",
        "    return A3, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udqVmo2X5BUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_cost(A3, Y, parameters):\n",
        "    \"\"\"\n",
        "    \n",
        "    Arguments:\n",
        "    A3 -- The sigmoid output of the second activation, of shape (1, number of examples)\n",
        "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
        "    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n",
        "    \n",
        "    Returns:\n",
        "    cost -- cross-entropy cost given equation (13)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = Y.shape[1] # number of example\n",
        "\n",
        "    # Compute the cross-entropy cost\n",
        "    logprobs = np.multiply(np.log(A3), Y) + np.multiply((1 - Y), np.log(1 - A3))\n",
        "    cost = - np.sum(logprobs) / m    \n",
        "    \n",
        "    cost = np.squeeze(cost)     # makes sure cost is the dimension we expect. \n",
        "                                # E.g., turns [[17]] into 17 \n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "48LWf_rV5EMk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "  \n",
        "def backward_propagation(parameters, cache, X, Y):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation using the instructions above.\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing our parameters \n",
        "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
        "    X -- input data of shape (2, number of examples)\n",
        "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
        "    \n",
        "    Returns:\n",
        "    grads -- python dictionary containing your gradients with respect to different parameters\n",
        "    \"\"\"\n",
        "    m = X.shape[1]\n",
        "    \n",
        "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    W3 = parameters['W3']\n",
        "        \n",
        "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
        "    A1 = cache['A1']\n",
        "    A2 = cache['A2']\n",
        "    A3 = cache['A3']\n",
        "    \n",
        "    Z1 = cache['Z1']\n",
        "    Z2 = cache['Z2']\n",
        "    Z3 = cache['Z3']\n",
        "    \n",
        "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
        "\n",
        "    dZ3 = A3-Y\n",
        "    dW3 = (1./m) * np.matmul(dZ3, A2.T)\n",
        "    db3 = (1./m) * np.sum(dZ3, axis=1, keepdims=True)\n",
        "    \n",
        "    dA2 = np.matmul(W3.T,dZ3)\n",
        "    dZ2 = dA2 * sigmoid(Z2) * (1 - sigmoid(Z2))\n",
        "    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n",
        "    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "    \n",
        "    dA1 = np.matmul(W2.T, dZ2)\n",
        "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
        "    dW1 = (1./m) * np.matmul(dZ1, X.T)\n",
        "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "    \n",
        "    grads = {\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\": dW2,\n",
        "             \"db2\": db2,\n",
        "             \"dW3\": dW3,\n",
        "             \"db3\": db3}\n",
        "    \n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eo5-VcyL5IZE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, grads, learning_rate = 1):\n",
        "    \"\"\"\n",
        "    Updates parameters using the gradient descent update rule given above\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    grads -- python dictionary containing your gradients \n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "    \"\"\"\n",
        "    # Retrieve each parameter from the dictionary \"parameters\"\n",
        "\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "\n",
        "    \n",
        "    # Retrieve each gradient from the dictionary \"grads\"\n",
        "    dW1 = grads['dW1']\n",
        "    db1 = grads['db1']\n",
        "    dW2 = grads['dW2']\n",
        "    db2 = grads['db2']\n",
        "    dW3 = grads['dW3']\n",
        "    db3 = grads['db3']\n",
        "\n",
        "    \n",
        "    # Update rule for each parameter\n",
        "\n",
        "    W1 = W1 - learning_rate * dW1\n",
        "    b1 = b1 - learning_rate * db1\n",
        "    W2 = W2 - learning_rate * dW2\n",
        "    b2 = b2 - learning_rate * db2\n",
        "    W3 = W3 - learning_rate * dW3\n",
        "    b3 = b3 - learning_rate * db3\n",
        "    \n",
        "    #print (W2.shape)\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "    return parameters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WsysE8DN5M7z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X -- dataset of shape (2, number of examples)\n",
        "    Y -- labels of shape (1, number of examples)\n",
        "    n_h -- size of the hidden layer\n",
        "    num_iterations -- Number of iterations in gradient descent loop\n",
        "    print_cost -- if True, print the cost every 1000 iterations\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(3)\n",
        "    n_x = layer_sizes(X, Y)[0]\n",
        "    n_y = layer_sizes(X, Y)[2]\n",
        "    \n",
        "    # Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations+1):\n",
        "         \n",
        "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
        "        A2, cache = forward_propagation(X, parameters)\n",
        "        \n",
        "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
        "        cost = compute_cost(A2, Y, parameters)\n",
        " \n",
        "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
        "        grads = backward_propagation(parameters, cache, X, Y)\n",
        " \n",
        "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
        "        parameters = update_parameters(parameters, grads)\n",
        "        \n",
        "        # Print the cost every 1000 iterations\n",
        "        if print_cost and i % 1000 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "\n",
        "    return parameters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNxfUJSy5RlJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(parameters, X):\n",
        "    \"\"\"\n",
        "    Using the learned parameters, predicts a class for each example in X\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    X -- input data of size (n_x, m)\n",
        "    \n",
        "    Returns\n",
        "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "    A2, cache = forward_propagation(X,parameters)\n",
        "    predictions = A2 > 0.5\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EeoTXRza5ULb",
        "colab_type": "code",
        "outputId": "734af3d4-c7a9-4310-887b-7f1fb3d2a96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "# Build a model with a n_h-dimensional hidden layer\n",
        "parameters = nn_model(X, Y, n_h = 3, num_iterations = 5000, print_cost=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3)\n",
            "Cost after iteration 0: 0.694972\n",
            "Cost after iteration 1000: 0.015882\n",
            "Cost after iteration 2000: 0.005903\n",
            "Cost after iteration 3000: 0.003597\n",
            "Cost after iteration 4000: 0.002582\n",
            "Cost after iteration 5000: 0.002013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_vFs3En55ZLh",
        "colab_type": "code",
        "outputId": "49c08db9-bcd8-45f4-f215-515d1048a3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = predict(parameters, X)\n",
        "print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G_uU7QpuF_UV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Minimum Number of layers required for 100% classification -  4"
      ]
    },
    {
      "metadata": {
        "id": "YxvL7IQY-FjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "W1 = parameters['W1']\n",
        "b1 = parameters['b1']\n",
        "W2 = parameters['W2']\n",
        "b2 = parameters['b2']\n",
        "W3 = parameters['W3']\n",
        "b3 = parameters['b3']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yY33eOkbGo6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Weights "
      ]
    },
    {
      "metadata": {
        "id": "YJL_tGIgDNBb",
        "colab_type": "code",
        "outputId": "8db5c546-c618-429b-df4e-02fb1506eca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"Weight for layer 1\\n\\n\" , W1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight for layer 1\n",
            "\n",
            " [[-2.51706688  0.88791395]\n",
            " [-3.5043297   1.13917446]\n",
            " [ 1.63522824  4.01357372]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VA7roHXgDN8L",
        "colab_type": "code",
        "outputId": "11b34e12-ce01-430d-cd0c-6972747b45d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"Bias for layer 1\\n\\n\" , b1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bias for layer 1\n",
            "\n",
            " [[ 0.58770871]\n",
            " [ 1.0726067 ]\n",
            " [-2.78339359]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yj0weQYnDO7W",
        "colab_type": "code",
        "outputId": "061b936f-65ac-42ac-cca3-498abd3781e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"Weight for layer 2\\n\\n\" , W2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight for layer 2\n",
            "\n",
            " [[-3.81384199 -3.44639334 -5.37715882]\n",
            " [-3.50655894 -5.8449524   6.40830704]\n",
            " [-2.15141904 -3.31904782  8.31979066]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xzh5YdGnDQzr",
        "colab_type": "code",
        "outputId": "4c0a46df-884e-44a5-a86c-be53b1c56780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"Bias for layer 2\\n\\n\" , b2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bias for layer 2\n",
            "\n",
            " [[ 1.67513854]\n",
            " [-2.20559248]\n",
            " [ 1.3557318 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OK5mWAG4DRtj",
        "colab_type": "code",
        "outputId": "33ceded5-bba3-468a-8741-1e4f9268e169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"Weight for layer 3\\n\\n\" , W3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weight for layer 3\n",
            "\n",
            " [[  6.70307033 -13.21091358  12.28892327]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rjvL6rsWH5FM",
        "colab_type": "code",
        "outputId": "7e44cf46-46f4-4b43-afe5-0a3f7ac22e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"Bias for layer 3\\n\\n\" , b3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bias for layer 3\n",
            "\n",
            " [[-6.10121865]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "laD8Su2BIJ8U",
        "colab_type": "code",
        "outputId": "e87f095a-defa-4946-f391-6bf2b16a1787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "W2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 337
        }
      ]
    },
    {
      "metadata": {
        "id": "Dh2oJ_-lHNLA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Learning rate used - 0.9"
      ]
    },
    {
      "metadata": {
        "id": "uoEYRcBaHYSr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Sigmoidal Slope Parameter - 1"
      ]
    },
    {
      "metadata": {
        "id": "mbJGXYqbHscl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Number of epochs for convergence - 5000"
      ]
    },
    {
      "metadata": {
        "id": "attEWkkDE4xO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "izT7-93rE7I8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}